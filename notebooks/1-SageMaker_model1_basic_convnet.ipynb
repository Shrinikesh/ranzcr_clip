{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: astor==0.8.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 4)) (0.8.1)\n",
      "Requirement already satisfied: backcall==0.1.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 7)) (0.1.0)\n",
      "Requirement already satisfied: chardet==3.0.4 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 13)) (3.0.4)\n",
      "Requirement already satisfied: colorama==0.4.3 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 15)) (0.4.3)\n",
      "Requirement already satisfied: cycler==0.10.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 17)) (0.10.0)\n",
      "Requirement already satisfied: defusedxml==0.6.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 19)) (0.6.0)\n",
      "Requirement already satisfied: docutils==0.15.2 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 20)) (0.15.2)\n",
      "Requirement already satisfied: entrypoints==0.3 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 21)) (0.3)\n",
      "Requirement already satisfied: gast==0.2.2 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 22)) (0.2.2)\n",
      "Requirement already satisfied: google-pasta==0.2.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 25)) (0.2.0)\n",
      "Requirement already satisfied: h5py==2.10.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 27)) (2.10.0)\n",
      "Requirement already satisfied: ipython-genutils==0.2.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 32)) (0.2.0)\n",
      "Requirement already satisfied: ipywidgets==7.5.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 33)) (7.5.1)\n",
      "Requirement already satisfied: joblib==0.14.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 38)) (0.14.1)\n",
      "Requirement already satisfied: jsonschema==3.2.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 39)) (3.2.0)\n",
      "Requirement already satisfied: jupyter==1.0.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 40)) (1.0.0)\n",
      "Requirement already satisfied: Keras==2.3.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 45)) (2.3.1)\n",
      "Requirement already satisfied: Keras-Applications==1.0.8 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 46)) (1.0.8)\n",
      "Requirement already satisfied: Keras-Preprocessing==1.1.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 47)) (1.1.0)\n",
      "Requirement already satisfied: kiwisolver==1.1.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 48)) (1.1.0)\n",
      "Requirement already satisfied: MarkupSafe==1.1.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 50)) (1.1.1)\n",
      "Requirement already satisfied: mistune==0.8.4 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 52)) (0.8.4)\n",
      "Requirement already satisfied: nbconvert==5.6.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 53)) (5.6.1)\n",
      "Requirement already satisfied: pandocfilters==1.4.2 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 60)) (1.4.2)\n",
      "Requirement already satisfied: pexpect==4.8.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 63)) (4.8.0)\n",
      "Requirement already satisfied: pickleshare==0.7.5 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 64)) (0.7.5)\n",
      "Requirement already satisfied: prometheus-client==0.7.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 67)) (0.7.1)\n",
      "Requirement already satisfied: ptyprocess==0.6.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 69)) (0.6.0)\n",
      "Requirement already satisfied: pyasn1==0.4.8 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 70)) (0.4.8)\n",
      "Requirement already satisfied: Pygments==2.5.2 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 72)) (2.5.2)\n",
      "Requirement already satisfied: pyparsing==2.4.7 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 73)) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil==2.8.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 75)) (2.8.1)\n",
      "Requirement already satisfied: pytz==2019.3 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 77)) (2019.3)\n",
      "Requirement already satisfied: PyYAML==5.3.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 78)) (5.3.1)\n",
      "Requirement already satisfied: QtPy==1.9.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 81)) (1.9.0)\n",
      "Requirement already satisfied: rsa in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 84)) (4.5)\n",
      "Requirement already satisfied: s3transfer==0.3.3 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 85)) (0.3.3)\n",
      "Requirement already satisfied: scipy==1.4.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 87)) (1.4.1)\n",
      "Requirement already satisfied: Send2Trash==1.5.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 89)) (1.5.0)\n",
      "Requirement already satisfied: termcolor==1.1.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 94)) (1.1.0)\n",
      "Requirement already satisfied: testpath==0.4.4 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 95)) (0.4.4)\n",
      "Requirement already satisfied: traitlets==4.3.3 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 99)) (4.3.3)\n",
      "Requirement already satisfied: webencodings==0.5.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 102)) (0.5.1)\n",
      "Requirement already satisfied: widgetsnbextension==3.5.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 104)) (3.5.1)\n",
      "Collecting absl-py==0.9.0\n",
      "  Using cached absl-py-0.9.0.tar.gz (104 kB)\n",
      "Collecting appnope==0.1.0\n",
      "  Using cached appnope-0.1.0-py2.py3-none-any.whl (4.0 kB)\n",
      "Collecting arrow==0.15.6\n",
      "  Using cached arrow-0.15.6-py2.py3-none-any.whl (47 kB)\n",
      "Requirement already satisfied: python-dateutil==2.8.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 75)) (2.8.1)\n",
      "Collecting attrs==19.3.0\n",
      "  Using cached attrs-19.3.0-py2.py3-none-any.whl (39 kB)\n",
      "Collecting awscli==1.18.46\n",
      "  Using cached awscli-1.18.46-py2.py3-none-any.whl (3.0 MB)\n",
      "Requirement already satisfied: docutils==0.15.2 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 20)) (0.15.2)\n",
      "Requirement already satisfied: PyYAML==5.3.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 78)) (5.3.1)\n",
      "Requirement already satisfied: colorama==0.4.3 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 15)) (0.4.3)\n",
      "Requirement already satisfied: s3transfer==0.3.3 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 85)) (0.3.3)\n",
      "Collecting binaryornot==0.4.4\n",
      "  Using cached binaryornot-0.4.4-py2.py3-none-any.whl (9.0 kB)\n",
      "Requirement already satisfied: chardet==3.0.4 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 13)) (3.0.4)\n",
      "Collecting bleach==3.1.4\n",
      "  Using cached bleach-3.1.4-py2.py3-none-any.whl (151 kB)\n",
      "Requirement already satisfied: webencodings==0.5.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 102)) (0.5.1)\n",
      "Collecting botocore==1.15.46\n",
      "  Using cached botocore-1.15.46-py2.py3-none-any.whl (6.1 MB)\n",
      "Requirement already satisfied: docutils==0.15.2 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 20)) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil==2.8.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 75)) (2.8.1)\n",
      "Collecting cachetools==3.1.1\n",
      "  Using cached cachetools-3.1.1-py2.py3-none-any.whl (11 kB)\n",
      "Collecting certifi==2020.4.5.1\n",
      "  Using cached certifi-2020.4.5.1-py2.py3-none-any.whl (157 kB)\n",
      "Collecting click==7.1.2\n",
      "  Using cached click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Collecting cookiecutter==1.7.2\n",
      "  Using cached cookiecutter-1.7.2-py2.py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: MarkupSafe==1.1.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 50)) (1.1.1)\n",
      "Collecting decorator==4.4.2\n",
      "  Using cached decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
      "Collecting google-auth==1.14.2\n",
      "  Using cached google_auth-1.14.2-py2.py3-none-any.whl (89 kB)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from google-auth==1.14.2->-r ../requirements.txt (line 23)) (45.2.0.post20200210)\n",
      "Collecting google-auth-oauthlib==0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.1-py2.py3-none-any.whl (18 kB)\n",
      "Collecting grpcio==1.28.1\n",
      "  Using cached grpcio-1.28.1-cp36-cp36m-manylinux2010_x86_64.whl (2.8 MB)\n",
      "Collecting idna==2.9\n",
      "  Using cached idna-2.9-py2.py3-none-any.whl (58 kB)\n",
      "Collecting importlib-metadata==1.6.0\n",
      "  Using cached importlib_metadata-1.6.0-py2.py3-none-any.whl (30 kB)\n",
      "Collecting ipykernel==4.10.1\n",
      "  Using cached ipykernel-4.10.1-py3-none-any.whl (109 kB)\n",
      "Requirement already satisfied: traitlets==4.3.3 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 99)) (4.3.3)\n",
      "Collecting ipython==5.10.0\n",
      "  Using cached ipython-5.10.0-py3-none-any.whl (760 kB)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from ipython==5.10.0->-r ../requirements.txt (line 31)) (0.8.1)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from google-auth==1.14.2->-r ../requirements.txt (line 23)) (45.2.0.post20200210)\n",
      "Requirement already satisfied: pexpect==4.8.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 63)) (4.8.0)\n",
      "Requirement already satisfied: traitlets==4.3.3 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 99)) (4.3.3)\n",
      "Requirement already satisfied: Pygments==2.5.2 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 72)) (2.5.2)\n",
      "Requirement already satisfied: pickleshare==0.7.5 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 64)) (0.7.5)\n",
      "Requirement already satisfied: widgetsnbextension==3.5.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 104)) (3.5.1)\n",
      "Requirement already satisfied: traitlets==4.3.3 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 99)) (4.3.3)\n",
      "Collecting jedi==0.17.0\n",
      "  Using cached jedi-0.17.0-py2.py3-none-any.whl (1.1 MB)\n",
      "Collecting Jinja2==2.11.2\n",
      "  Using cached Jinja2-2.11.2-py2.py3-none-any.whl (125 kB)\n",
      "Requirement already satisfied: MarkupSafe==1.1.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 50)) (1.1.1)\n",
      "Collecting jinja2-time==0.2.0\n",
      "  Using cached jinja2_time-0.2.0-py2.py3-none-any.whl (6.4 kB)\n",
      "Collecting jmespath==0.9.5\n",
      "  Using cached jmespath-0.9.5-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from google-auth==1.14.2->-r ../requirements.txt (line 23)) (45.2.0.post20200210)\n",
      "Requirement already satisfied: ipywidgets==7.5.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 33)) (7.5.1)\n",
      "Requirement already satisfied: nbconvert==5.6.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 53)) (5.6.1)\n",
      "Collecting jupyter-client==5.3.5\n",
      "  Using cached jupyter_client-5.3.5-py2.py3-none-any.whl (92 kB)\n",
      "Requirement already satisfied: traitlets==4.3.3 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 99)) (4.3.3)\n",
      "Requirement already satisfied: python-dateutil==2.8.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 75)) (2.8.1)\n",
      "Collecting jupyter-console==5.2.0\n",
      "  Using cached jupyter_console-5.2.0-py2.py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: Pygments==2.5.2 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 72)) (2.5.2)\n",
      "Collecting jupyter-core==4.6.3\n",
      "  Using cached jupyter_core-4.6.3-py2.py3-none-any.whl (83 kB)\n",
      "Requirement already satisfied: traitlets==4.3.3 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 99)) (4.3.3)\n",
      "Collecting kaggle==1.5.10\n",
      "  Using cached kaggle-1.5.10.tar.gz (59 kB)\n",
      "Requirement already satisfied: python-dateutil==2.8.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 75)) (2.8.1)\n",
      "Requirement already satisfied: Keras-Applications==1.0.8 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 46)) (1.0.8)\n",
      "Requirement already satisfied: scipy==1.4.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 87)) (1.4.1)\n",
      "Requirement already satisfied: Keras-Preprocessing==1.1.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 47)) (1.1.0)\n",
      "Requirement already satisfied: PyYAML==5.3.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 78)) (5.3.1)\n",
      "Requirement already satisfied: h5py==2.10.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 27)) (2.10.0)\n",
      "Requirement already satisfied: h5py==2.10.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 27)) (2.10.0)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from google-auth==1.14.2->-r ../requirements.txt (line 23)) (45.2.0.post20200210)\n",
      "Collecting Markdown==3.1.1\n",
      "  Using cached Markdown-3.1.1-py2.py3-none-any.whl (87 kB)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from google-auth==1.14.2->-r ../requirements.txt (line 23)) (45.2.0.post20200210)\n",
      "Collecting matplotlib==2.2.5\n",
      "  Using cached matplotlib-2.2.5-cp36-cp36m-manylinux1_x86_64.whl (12.8 MB)\n",
      "Requirement already satisfied: python-dateutil==2.8.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 75)) (2.8.1)\n",
      "Requirement already satisfied: cycler==0.10.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 17)) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver==1.1.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 48)) (1.1.0)\n",
      "Requirement already satisfied: pyparsing==2.4.7 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 73)) (2.4.7)\n",
      "Requirement already satisfied: pytz==2019.3 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 77)) (2019.3)\n",
      "Requirement already satisfied: defusedxml==0.6.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 19)) (0.6.0)\n",
      "Requirement already satisfied: testpath==0.4.4 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 95)) (0.4.4)\n",
      "Requirement already satisfied: pandocfilters==1.4.2 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 60)) (1.4.2)\n",
      "Requirement already satisfied: traitlets==4.3.3 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 99)) (4.3.3)\n",
      "Requirement already satisfied: entrypoints==0.3 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 21)) (0.3)\n",
      "Requirement already satisfied: mistune==0.8.4 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 52)) (0.8.4)\n",
      "Requirement already satisfied: Pygments==2.5.2 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 72)) (2.5.2)\n",
      "Collecting nbformat==4.4.0\n",
      "  Using cached nbformat-4.4.0-py2.py3-none-any.whl (155 kB)\n",
      "Requirement already satisfied: jsonschema==3.2.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 39)) (3.2.0)\n",
      "Requirement already satisfied: ipython-genutils==0.2.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 32)) (0.2.0)\n",
      "Requirement already satisfied: traitlets==4.3.3 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 99)) (4.3.3)\n",
      "Collecting notebook==5.7.10\n",
      "  Using cached notebook-5.7.10-py2.py3-none-any.whl (9.6 MB)\n",
      "Requirement already satisfied: nbconvert==5.6.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 53)) (5.6.1)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from notebook==5.7.10->-r ../requirements.txt (line 55)) (0.8.3)\n",
      "Requirement already satisfied: prometheus-client==0.7.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 67)) (0.7.1)\n",
      "Requirement already satisfied: ipython-genutils==0.2.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 32)) (0.2.0)\n",
      "Requirement already satisfied: traitlets==4.3.3 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 99)) (4.3.3)\n",
      "Requirement already satisfied: Send2Trash==1.5.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 89)) (1.5.0)\n",
      "Collecting numpy==1.16.6\n",
      "  Using cached numpy-1.16.6-cp36-cp36m-manylinux1_x86_64.whl (17.4 MB)\n",
      "Collecting oauthlib==3.1.0\n",
      "  Using cached oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Collecting opt-einsum==2.3.2\n",
      "  Using cached opt_einsum-2.3.2.tar.gz (59 kB)\n",
      "Collecting pandas==0.24.2\n",
      "  Using cached pandas-0.24.2-cp36-cp36m-manylinux1_x86_64.whl (10.1 MB)\n",
      "Requirement already satisfied: python-dateutil==2.8.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 75)) (2.8.1)\n",
      "Requirement already satisfied: pytz==2019.3 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 77)) (2019.3)\n",
      "Collecting parso==0.7.0\n",
      "  Using cached parso-0.7.0-py2.py3-none-any.whl (100 kB)\n",
      "Collecting pathlib\n",
      "  Using cached pathlib-1.0.1.tar.gz (49 kB)\n",
      "Requirement already satisfied: ptyprocess==0.6.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 69)) (0.6.0)\n",
      "Collecting Pillow==6.2.2\n",
      "  Using cached Pillow-6.2.2-cp36-cp36m-manylinux1_x86_64.whl (2.1 MB)\n",
      "Collecting poyo==0.5.0\n",
      "  Using cached poyo-0.5.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting protobuf==3.11.3\n",
      "  Using cached protobuf-3.11.3-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from google-auth==1.14.2->-r ../requirements.txt (line 23)) (45.2.0.post20200210)\n",
      "Collecting pyasn1-modules==0.2.8\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Requirement already satisfied: pyasn1==0.4.8 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 70)) (0.4.8)\n",
      "Collecting pyrsistent==0.16.0\n",
      "  Using cached pyrsistent-0.16.0.tar.gz (108 kB)\n",
      "Collecting python-slugify==4.0.0\n",
      "  Using cached python-slugify-4.0.0.tar.gz (8.8 kB)\n",
      "Collecting pyzmq==19.0.0\n",
      "  Using cached pyzmq-19.0.0-cp36-cp36m-manylinux1_x86_64.whl (1.1 MB)\n",
      "Collecting qtconsole==4.7.3\n",
      "  Using cached qtconsole-4.7.3-py2.py3-none-any.whl (117 kB)\n",
      "Requirement already satisfied: traitlets==4.3.3 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 99)) (4.3.3)\n",
      "Requirement already satisfied: ipython-genutils==0.2.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 32)) (0.2.0)\n",
      "Requirement already satisfied: QtPy==1.9.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 81)) (1.9.0)\n",
      "Requirement already satisfied: Pygments==2.5.2 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 72)) (2.5.2)\n",
      "Collecting requests==2.23.0\n",
      "  Using cached requests-2.23.0-py2.py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: chardet==3.0.4 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 13)) (3.0.4)\n",
      "Collecting requests-oauthlib==1.3.0\n",
      "  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting rsa\n",
      "  Using cached rsa-3.4.2-py2.py3-none-any.whl (46 kB)\n",
      "Requirement already satisfied: pyasn1==0.4.8 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 70)) (0.4.8)\n",
      "Collecting scikit-learn==0.20.4\n",
      "  Using cached scikit_learn-0.20.4-cp36-cp36m-manylinux1_x86_64.whl (5.4 MB)\n",
      "Requirement already satisfied: scipy==1.4.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 87)) (1.4.1)\n",
      "Collecting seaborn==0.9.1\n",
      "  Using cached seaborn-0.9.1-py2.py3-none-any.whl (216 kB)\n",
      "Requirement already satisfied: scipy==1.4.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 87)) (1.4.1)\n",
      "Collecting six==1.14.0\n",
      "  Using cached six-1.14.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting tensorboard==2.1.0\n",
      "  Using cached tensorboard-2.1.0-py3-none-any.whl (3.8 MB)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from google-auth==1.14.2->-r ../requirements.txt (line 23)) (45.2.0.post20200210)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from tensorboard==2.1.0->-r ../requirements.txt (line 91)) (0.34.2)\n",
      "Collecting tensorflow==2.1.0\n",
      "  Using cached tensorflow-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8 MB)\n",
      "Requirement already satisfied: termcolor==1.1.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 94)) (1.1.0)\n",
      "Requirement already satisfied: scipy==1.4.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 87)) (1.4.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from tensorboard==2.1.0->-r ../requirements.txt (line 91)) (0.34.2)\n",
      "Requirement already satisfied: Keras-Applications==1.0.8 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 46)) (1.0.8)\n",
      "Requirement already satisfied: gast==0.2.2 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 22)) (0.2.2)\n",
      "Requirement already satisfied: google-pasta==0.2.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 25)) (0.2.0)\n",
      "Requirement already satisfied: astor==0.8.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 4)) (0.8.1)\n",
      "Requirement already satisfied: Keras-Preprocessing==1.1.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 47)) (1.1.0)\n",
      "Collecting tensorflow-estimator==2.1.0\n",
      "  Using cached tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448 kB)\n",
      "Collecting text-unidecode==1.3\n",
      "  Using cached text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "Collecting tornado==5.1.1\n",
      "  Downloading tornado-5.1.1.tar.gz (516 kB)\n",
      "\u001b[K     |████████████████████████████████| 516 kB 6.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tqdm==4.54.1\n",
      "  Using cached tqdm-4.54.1-py2.py3-none-any.whl (69 kB)\n",
      "Requirement already satisfied: ipython-genutils==0.2.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from -r ../requirements.txt (line 32)) (0.2.0)\n",
      "Collecting urllib3==1.25.9\n",
      "  Using cached urllib3-1.25.9-py2.py3-none-any.whl (126 kB)\n",
      "Collecting wcwidth==0.1.9\n",
      "  Using cached wcwidth-0.1.9-py2.py3-none-any.whl (19 kB)\n",
      "Collecting Werkzeug==1.0.1\n",
      "  Using cached Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "Collecting wrapt==1.12.1\n",
      "  Using cached wrapt-1.12.1.tar.gz (27 kB)\n",
      "Collecting zipp==1.2.0\n",
      "  Using cached zipp-1.2.0-py2.py3-none-any.whl (4.8 kB)\n",
      "Collecting prompt-toolkit<2.0.0,>=1.0.4\n",
      "  Downloading prompt_toolkit-1.0.18-py3-none-any.whl (245 kB)\n",
      "\u001b[K     |████████████████████████████████| 245 kB 12.5 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: absl-py, kaggle, opt-einsum, pathlib, pyrsistent, python-slugify, tornado, wrapt\n",
      "  Building wheel for absl-py (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for absl-py: filename=absl_py-0.9.0-py3-none-any.whl size=121931 sha256=d9723b97feeff68d707844c78cd617d1c84c8f3fb42f3a25a8e6bc1a68ea8c6d\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/c3/af/84/3962a6af7b4ab336e951b7877dcfb758cf94548bb1771e0679\n",
      "  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.5.10-py3-none-any.whl size=73269 sha256=5a8ffc8aa5a2a3c4477d16fd79f982d2e4be89540f5d27960018fe3142b03cf2\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/1c/dd/dd/c493e6f981182c1411e288c553310f76e212bac3afbdac1294\n",
      "  Building wheel for opt-einsum (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for opt-einsum: filename=opt_einsum-2.3.2-py3-none-any.whl size=49881 sha256=d3be969de3c201542f90addd46082bae269abf921db7ab85b26f2d360c851bf5\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/09/20/0e/ab2dc7abc8ee39da053360978b48d2947652949c22133e49ac\n",
      "  Building wheel for pathlib (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pathlib: filename=pathlib-1.0.1-py3-none-any.whl size=14346 sha256=bd76c8e477cfbb9df54e421773b3931564ba47352124b6c075ca3b9b64f0e1c9\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/e1/32/91/afe2cabe6f77819de11759f2a07d538cd521ef3a9dd81ba0b4\n",
      "  Building wheel for pyrsistent (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyrsistent: filename=pyrsistent-0.16.0-cp36-cp36m-linux_x86_64.whl size=114645 sha256=9848897fbaacbb6f8943127ae831f42f1fdc0dee79e5eadf8ec66b554165d823\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/d1/8a/1c/32ab9017418a2c64e4fbaf503c08648bed2f8eb311b869a464\n",
      "  Building wheel for python-slugify (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for python-slugify: filename=python_slugify-4.0.0-py2.py3-none-any.whl size=5486 sha256=0adec94d7bf3653b6a8a8294267dd045f227b4d38a4b2d075da051a435c6c575\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/5f/a9/4b/aa1ee60ccbd4389a2fe11c9b94adf3d9fa61cecda46c1187a9\n",
      "  Building wheel for tornado (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for tornado: filename=tornado-5.1.1-cp36-cp36m-linux_x86_64.whl size=457627 sha256=10ae425a11650c66cd327db52c5805e29c4d2c683eac5fd01ffc5b6021e820cc\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/64/74/71/e7a0d0eb4fc42cb20a17aec36f8f0b5b8c5e1ec19c701fd34a\n",
      "  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wrapt: filename=wrapt-1.12.1-cp36-cp36m-linux_x86_64.whl size=66709 sha256=347796d946301d1fbe31cb122a68a8d8bf8b9836c787e0d78b2e6e8f3e338da5\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/32/42/7f/23cae9ff6ef66798d00dc5d659088e57dbba01566f6c60db63\n",
      "Successfully built absl-py kaggle opt-einsum pathlib pyrsistent python-slugify tornado wrapt\n",
      "Installing collected packages: zipp, six, decorator, wcwidth, pyrsistent, importlib-metadata, attrs, tornado, pyzmq, prompt-toolkit, jupyter-core, urllib3, nbformat, jupyter-client, Jinja2, ipython, idna, certifi, bleach, rsa, requests, pyasn1-modules, oauthlib, ipykernel, cachetools, requests-oauthlib, numpy, notebook, jmespath, google-auth, Werkzeug, text-unidecode, protobuf, Markdown, grpcio, google-auth-oauthlib, botocore, arrow, absl-py, wrapt, tqdm, tensorflow-estimator, tensorboard, qtconsole, python-slugify, poyo, parso, pandas, opt-einsum, matplotlib, jupyter-console, jinja2-time, click, binaryornot, tensorflow, seaborn, scikit-learn, Pillow, pathlib, kaggle, jedi, cookiecutter, awscli, appnope\n",
      "  Attempting uninstall: zipp\n",
      "    Found existing installation: zipp 3.4.0\n",
      "    Uninstalling zipp-3.4.0:\n",
      "      Successfully uninstalled zipp-3.4.0\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.15.0\n",
      "    Uninstalling six-1.15.0:\n",
      "      Successfully uninstalled six-1.15.0\n",
      "  Attempting uninstall: decorator\n",
      "    Found existing installation: decorator 4.4.1\n",
      "    Uninstalling decorator-4.4.1:\n",
      "      Successfully uninstalled decorator-4.4.1\n",
      "  Attempting uninstall: wcwidth\n",
      "    Found existing installation: wcwidth 0.1.8\n",
      "    Uninstalling wcwidth-0.1.8:\n",
      "      Successfully uninstalled wcwidth-0.1.8\n",
      "  Attempting uninstall: pyrsistent\n",
      "    Found existing installation: pyrsistent 0.15.7\n",
      "    Uninstalling pyrsistent-0.15.7:\n",
      "      Successfully uninstalled pyrsistent-0.15.7\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 3.1.0\n",
      "    Uninstalling importlib-metadata-3.1.0:\n",
      "      Successfully uninstalled importlib-metadata-3.1.0\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 20.3.0\n",
      "    Uninstalling attrs-20.3.0:\n",
      "      Successfully uninstalled attrs-20.3.0\n",
      "  Attempting uninstall: tornado\n",
      "    Found existing installation: tornado 6.0.3\n",
      "    Uninstalling tornado-6.0.3:\n",
      "      Successfully uninstalled tornado-6.0.3\n",
      "  Attempting uninstall: pyzmq\n",
      "    Found existing installation: pyzmq 18.1.1\n",
      "    Uninstalling pyzmq-18.1.1:\n",
      "      Successfully uninstalled pyzmq-18.1.1\n",
      "  Attempting uninstall: prompt-toolkit\n",
      "    Found existing installation: prompt-toolkit 3.0.3\n",
      "    Uninstalling prompt-toolkit-3.0.3:\n",
      "      Successfully uninstalled prompt-toolkit-3.0.3\n",
      "  Attempting uninstall: jupyter-core\n",
      "    Found existing installation: jupyter-core 4.6.1\n",
      "    Uninstalling jupyter-core-4.6.1:\n",
      "      Successfully uninstalled jupyter-core-4.6.1\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.25.11\n",
      "    Uninstalling urllib3-1.25.11:\n",
      "      Successfully uninstalled urllib3-1.25.11\n",
      "  Attempting uninstall: nbformat\n",
      "    Found existing installation: nbformat 5.0.4\n",
      "    Uninstalling nbformat-5.0.4:\n",
      "      Successfully uninstalled nbformat-5.0.4\n",
      "  Attempting uninstall: jupyter-client\n",
      "    Found existing installation: jupyter-client 5.3.4\n",
      "    Uninstalling jupyter-client-5.3.4:\n",
      "      Successfully uninstalled jupyter-client-5.3.4\n",
      "  Attempting uninstall: Jinja2\n",
      "    Found existing installation: Jinja2 2.11.1\n",
      "    Uninstalling Jinja2-2.11.1:\n",
      "      Successfully uninstalled Jinja2-2.11.1\n",
      "  Attempting uninstall: ipython\n",
      "    Found existing installation: ipython 7.12.0\n",
      "    Uninstalling ipython-7.12.0:\n",
      "      Successfully uninstalled ipython-7.12.0\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 2.10\n",
      "    Uninstalling idna-2.10:\n",
      "      Successfully uninstalled idna-2.10\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2020.11.8\n",
      "    Uninstalling certifi-2020.11.8:\n",
      "      Successfully uninstalled certifi-2020.11.8\n",
      "  Attempting uninstall: bleach\n",
      "    Found existing installation: bleach 3.2.1\n",
      "    Uninstalling bleach-3.2.1:\n",
      "      Successfully uninstalled bleach-3.2.1\n",
      "  Attempting uninstall: rsa\n",
      "    Found existing installation: rsa 4.5\n",
      "    Uninstalling rsa-4.5:\n",
      "      Successfully uninstalled rsa-4.5\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.25.0\n",
      "    Uninstalling requests-2.25.0:\n",
      "      Successfully uninstalled requests-2.25.0\n",
      "  Attempting uninstall: ipykernel\n",
      "    Found existing installation: ipykernel 5.1.4\n",
      "    Uninstalling ipykernel-5.1.4:\n",
      "      Successfully uninstalled ipykernel-5.1.4\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.4\n",
      "    Uninstalling numpy-1.19.4:\n",
      "      Successfully uninstalled numpy-1.19.4\n",
      "  Attempting uninstall: notebook\n",
      "    Found existing installation: notebook 6.0.3\n",
      "    Uninstalling notebook-6.0.3:\n",
      "      Successfully uninstalled notebook-6.0.3\n",
      "  Attempting uninstall: jmespath\n",
      "    Found existing installation: jmespath 0.10.0\n",
      "    Uninstalling jmespath-0.10.0:\n",
      "      Successfully uninstalled jmespath-0.10.0\n",
      "  Attempting uninstall: Werkzeug\n",
      "    Found existing installation: Werkzeug 1.0.0\n",
      "    Uninstalling Werkzeug-1.0.0:\n",
      "      Successfully uninstalled Werkzeug-1.0.0\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.14.0\n",
      "    Uninstalling protobuf-3.14.0:\n",
      "      Successfully uninstalled protobuf-3.14.0\n",
      "  Attempting uninstall: Markdown\n",
      "    Found existing installation: Markdown 3.3.3\n",
      "    Uninstalling Markdown-3.3.3:\n",
      "      Successfully uninstalled Markdown-3.3.3\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.33.2\n",
      "    Uninstalling grpcio-1.33.2:\n",
      "      Successfully uninstalled grpcio-1.33.2\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.19.37\n",
      "    Uninstalling botocore-1.19.37:\n",
      "      Successfully uninstalled botocore-1.19.37\n",
      "  Attempting uninstall: absl-py\n",
      "    Found existing installation: absl-py 0.11.0\n",
      "    Uninstalling absl-py-0.11.0:\n",
      "      Successfully uninstalled absl-py-0.11.0\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.11.2\n",
      "    Uninstalling wrapt-1.11.2:\n",
      "      Successfully uninstalled wrapt-1.11.2\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.42.1\n",
      "    Uninstalling tqdm-4.42.1:\n",
      "      Successfully uninstalled tqdm-4.42.1\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 1.15.1\n",
      "    Uninstalling tensorflow-estimator-1.15.1:\n",
      "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 1.15.0\n",
      "    Uninstalling tensorboard-1.15.0:\n",
      "      Successfully uninstalled tensorboard-1.15.0\n",
      "  Attempting uninstall: qtconsole\n",
      "    Found existing installation: qtconsole 4.6.0\n",
      "    Uninstalling qtconsole-4.6.0:\n",
      "      Successfully uninstalled qtconsole-4.6.0\n",
      "  Attempting uninstall: parso\n",
      "    Found existing installation: parso 0.5.2\n",
      "    Uninstalling parso-0.5.2:\n",
      "      Successfully uninstalled parso-0.5.2\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.0.1\n",
      "    Uninstalling pandas-1.0.1:\n",
      "      Successfully uninstalled pandas-1.0.1\n",
      "  Attempting uninstall: opt-einsum\n",
      "    Found existing installation: opt-einsum 3.3.0\n",
      "    Uninstalling opt-einsum-3.3.0:\n",
      "      Successfully uninstalled opt-einsum-3.3.0\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.1.3\n",
      "    Uninstalling matplotlib-3.1.3:\n",
      "      Successfully uninstalled matplotlib-3.1.3\n",
      "  Attempting uninstall: jupyter-console\n",
      "    Found existing installation: jupyter-console 6.1.0\n",
      "    Uninstalling jupyter-console-6.1.0:\n",
      "      Successfully uninstalled jupyter-console-6.1.0\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: Click 7.0\n",
      "    Uninstalling Click-7.0:\n",
      "      Successfully uninstalled Click-7.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 1.15.2\n",
      "    Uninstalling tensorflow-1.15.2:\n",
      "      Successfully uninstalled tensorflow-1.15.2\n",
      "  Attempting uninstall: seaborn\n",
      "    Found existing installation: seaborn 0.10.0\n",
      "    Uninstalling seaborn-0.10.0:\n",
      "      Successfully uninstalled seaborn-0.10.0\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.22.1\n",
      "    Uninstalling scikit-learn-0.22.1:\n",
      "      Successfully uninstalled scikit-learn-0.22.1\n",
      "  Attempting uninstall: Pillow\n",
      "    Found existing installation: Pillow 7.0.0\n",
      "    Uninstalling Pillow-7.0.0:\n",
      "      Successfully uninstalled Pillow-7.0.0\n",
      "  Attempting uninstall: jedi\n",
      "    Found existing installation: jedi 0.14.1\n",
      "    Uninstalling jedi-0.14.1:\n",
      "      Successfully uninstalled jedi-0.14.1\n",
      "  Attempting uninstall: awscli\n",
      "    Found existing installation: awscli 1.18.197\n",
      "    Uninstalling awscli-1.18.197:\n",
      "      Successfully uninstalled awscli-1.18.197\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 4.0.1 requires pyqt5<5.13; python_version >= \"3\", which is not installed.\n",
      "spyder 4.0.1 requires pyqtwebengine<5.13; python_version >= \"3\", which is not installed.\n",
      "pytest-astropy 0.8.0 requires pytest-cov>=2.0, which is not installed.\n",
      "pytest-astropy 0.8.0 requires pytest-filter-subpackage>=0.1, which is not installed.\n",
      "tensorflow-serving-api 1.15.0 requires tensorflow~=1.15.0, but you have tensorflow 2.1.0 which is incompatible.\n",
      "spyder 4.0.1 requires jedi==0.14.1, but you have jedi 0.17.0 which is incompatible.\n",
      "spyder-kernels 1.8.1 requires ipykernel>=5.1.3; python_version > \"2\", but you have ipykernel 4.10.1 which is incompatible.\n",
      "python-language-server 0.31.7 requires jedi<0.16,>=0.14.1, but you have jedi 0.17.0 which is incompatible.\n",
      "boto3 1.16.37 requires botocore<1.20.0,>=1.19.37, but you have botocore 1.15.46 which is incompatible.\u001b[0m\n",
      "Successfully installed Jinja2-2.11.2 Markdown-3.1.1 Pillow-6.2.2 Werkzeug-1.0.1 absl-py-0.9.0 appnope-0.1.0 arrow-0.15.6 attrs-19.3.0 awscli-1.18.46 binaryornot-0.4.4 bleach-3.1.4 botocore-1.15.46 cachetools-3.1.1 certifi-2020.11.8 click-7.1.2 cookiecutter-1.7.2 decorator-4.4.2 google-auth-1.14.2 google-auth-oauthlib-0.4.1 grpcio-1.28.1 idna-2.9 importlib-metadata-1.6.0 ipykernel-4.10.1 ipython-5.10.0 jedi-0.17.0 jinja2-time-0.2.0 jmespath-0.10.0 jupyter-client-5.3.5 jupyter-console-5.2.0 jupyter-core-4.6.3 kaggle-1.5.10 matplotlib-2.2.5 nbformat-4.4.0 notebook-5.7.10 numpy-1.18.1 oauthlib-3.1.0 opt-einsum-2.3.2 pandas-0.24.2 parso-0.7.0 pathlib-1.0.1 poyo-0.5.0 prompt-toolkit-1.0.18 protobuf-3.11.4 pyasn1-modules-0.2.8 pyrsistent-0.16.0 python-slugify-4.0.0 pyzmq-19.0.0 qtconsole-4.7.3 requests-2.23.0 requests-oauthlib-1.3.0 rsa-3.4.2 scikit-learn-0.20.4 seaborn-0.9.1 six-1.14.0 tensorboard-2.1.0 tensorflow-2.1.0 tensorflow-estimator-2.1.0 text-unidecode-1.3 tornado-5.1.1 tqdm-4.54.1 urllib3-1.25.10 wcwidth-0.1.9 wrapt-1.12.1 zipp-2.2.0\n",
      "\u001b[33mWARNING: You are using pip version 20.3; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import ast\n",
    "from sklearn.model_selection import KFold\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from keras import layers, Input\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "import keras\n",
    "from keras import backend\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handlers could be found for logger \"sagemaker\"\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'basic_convnet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Before defining the model, we will define an fbeta metric that we will monitor which we will use as a proxy for the average AUROC across the 11 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fbeta(y_true, y_pred, beta=2):\n",
    "    # taken from https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-to-classify-satellite-photos-of-the-amazon-rainforest/\n",
    "    #clip predictions (incase our output layer is not bound to [0,1])\n",
    "    y_pred = backend.clip(y_pred, 0, 1)\n",
    "    # calculate tp, fp and fn for each class\n",
    "    tp = backend.sum(backend.round(backend.clip(y_true * y_pred, 0, 1)), axis=1)\n",
    "    fp = backend.sum(backend.round(backend.clip(y_pred - y_true, 0, 1)), axis=1)\n",
    "    fn = backend.sum(backend.round(backend.clip(y_true - y_pred, 0, 1)), axis=1)\n",
    "    # calculate precision\n",
    "    p = tp / (tp + fp + backend.epsilon())\n",
    "    # calculate recall\n",
    "    r = tp / (tp + fn + backend.epsilon())\n",
    "    # calculate fbeta, averaged across each class\n",
    "    bb = beta ** 2\n",
    "    fbeta_score = backend.mean((1 + bb) * (p * r) / (bb * p + r + backend.epsilon()))\n",
    "    return fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_model(input_dim, output_dim):\n",
    "    input_tensor = Input(shape=(input_dim,input_dim,1))\n",
    "    y = layers.Conv2D(32, (3,3), padding='same', activation='relu')(input_tensor)\n",
    "    y = layers.MaxPooling2D(2, strides=2)(y)\n",
    "    y = layers.Conv2D(32, (3,3), padding='same', activation='relu')(y)\n",
    "    y = layers.MaxPooling2D(2, strides=2)(y)\n",
    "    y = layers.Dropout(0.25)(y)\n",
    "    \n",
    "    y = layers.Conv2D(64, (3,3), padding='same', activation='relu')(y)\n",
    "    y = layers.MaxPooling2D(2, strides=2)(y)\n",
    "    y = layers.Conv2D(128, (3,3), padding='same', activation='relu')(y)\n",
    "    y = layers.MaxPooling2D(2, strides=2)(y)\n",
    "    y = layers.Dropout(0.25)(y)\n",
    "    \n",
    "    y = layers.Flatten()(y)\n",
    "    y = layers.Dense(512, activation= 'relu')(y)\n",
    "    y = layers.Dropout(0.5)(y)\n",
    "    output_tensor = layers.Dense(output_dim, activation='sigmoid')(y)\n",
    "    \n",
    "    model = Model(input_tensor, output_tensor)\n",
    "    \n",
    "    \n",
    "    model.compile(optimizers.rmsprop(lr=0.0001, decay=1e-6),\n",
    "                 loss=\"binary_crossentropy\", metrics = [fbeta])\n",
    "    \n",
    "    return model\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_path = Path('/Users/Shrinikesh/Documents/personal-projects/kaggle/ranzcr_clip/data/raw')\n",
    "raw_image_data_path = Path('/Users/Shrinikesh/Documents/personal-projects/kaggle/ranzcr_clip/data/raw/train')\n",
    "models_dir = Path('/Users/Shrinikesh/Documents/personal-projects/kaggle/ranzcr_clip/models')\n",
    "train_data_path = raw_data_path / 'train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30083, 13)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will drop PatientID for now as it is not included in test images. Perhaps we can incorporate the information later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Moreover, as we need the filenames in full to use the flow_from_dataframe function for training, we will append the extension to all the StudyInstanceUIDs (.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_ext(fn):\n",
    "    return fn+\".jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>ETT - Abnormal</th>\n",
       "      <th>ETT - Borderline</th>\n",
       "      <th>ETT - Normal</th>\n",
       "      <th>NGT - Abnormal</th>\n",
       "      <th>NGT - Borderline</th>\n",
       "      <th>NGT - Incompletely Imaged</th>\n",
       "      <th>NGT - Normal</th>\n",
       "      <th>CVC - Abnormal</th>\n",
       "      <th>CVC - Borderline</th>\n",
       "      <th>CVC - Normal</th>\n",
       "      <th>Swan Ganz Catheter Present</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.826.0.1.3680043.8.498.26697628953273228189...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2.826.0.1.3680043.8.498.46302891597398758759...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.826.0.1.3680043.8.498.23819260719748494858...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.2.826.0.1.3680043.8.498.68286643202323212801...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.2.826.0.1.3680043.8.498.10050203009225938259...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    StudyInstanceUID  ETT - Abnormal  \\\n",
       "0  1.2.826.0.1.3680043.8.498.26697628953273228189...               0   \n",
       "1  1.2.826.0.1.3680043.8.498.46302891597398758759...               0   \n",
       "2  1.2.826.0.1.3680043.8.498.23819260719748494858...               0   \n",
       "3  1.2.826.0.1.3680043.8.498.68286643202323212801...               0   \n",
       "4  1.2.826.0.1.3680043.8.498.10050203009225938259...               0   \n",
       "\n",
       "   ETT - Borderline  ETT - Normal  NGT - Abnormal  NGT - Borderline  \\\n",
       "0                 0             0               0                 0   \n",
       "1                 0             1               0                 0   \n",
       "2                 0             0               0                 0   \n",
       "3                 0             0               0                 0   \n",
       "4                 0             0               0                 0   \n",
       "\n",
       "   NGT - Incompletely Imaged  NGT - Normal  CVC - Abnormal  CVC - Borderline  \\\n",
       "0                          0             1               0                 0   \n",
       "1                          1             0               0                 0   \n",
       "2                          0             0               0                 1   \n",
       "3                          0             0               1                 0   \n",
       "4                          0             0               0                 0   \n",
       "\n",
       "   CVC - Normal  Swan Ganz Catheter Present  \n",
       "0             0                           0  \n",
       "1             1                           0  \n",
       "2             0                           0  \n",
       "3             0                           0  \n",
       "4             1                           0  "
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_df['PatientID']\n",
    "\n",
    "train_df['StudyInstanceUID'] = train_df['StudyInstanceUID'].apply(append_ext)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = list(train_df.columns)\n",
    "class_names.remove('StudyInstanceUID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will create a class to index mapping so that the model will work irrespective of the order of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping = {class_names[i]:i for i in range(len(class_names))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ETT - Abnormal': 0,\n",
       " 'ETT - Borderline': 1,\n",
       " 'ETT - Normal': 2,\n",
       " 'NGT - Abnormal': 3,\n",
       " 'NGT - Borderline': 4,\n",
       " 'NGT - Incompletely Imaged': 5,\n",
       " 'NGT - Normal': 6,\n",
       " 'CVC - Abnormal': 7,\n",
       " 'CVC - Borderline': 8,\n",
       " 'CVC - Normal': 9,\n",
       " 'Swan Ganz Catheter Present': 10}"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will use stratified K-Fold validation for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to one hot encode each example's\n",
    "# labels as an array using the mapping\n",
    "\n",
    "def one_hot_encode(example_labels_dict, mapping=class_mapping):\n",
    "    encoding = np.zeros(len(mapping), dtype='uint8')\n",
    "    for label, value in example_labels_dict.items():\n",
    "        if value:\n",
    "            encoding[mapping[label]] = 1\n",
    "    return encoding        \n",
    "            \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = train_df[class_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 3\n",
    "\n",
    "kf = KFold(n_splits = n_splits, random_state = 7, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define percentage of overall data to use for training here (just as using all the data for training might take too long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_use_percent = 0.2\n",
    "\n",
    "n_samples = int(np.ceil(train_df.shape[0]*train_use_percent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6017"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will use ImageDataGenerator to turn our images into batches of preprocessed training and validation images during each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "idg = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We also need to save the best model during each fold, so will also create a function here that creates a model name for each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_name(k):\n",
    "    return 'model_{}.h5'.format(str(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAIN TRAINING LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2407 validated image filenames.\n",
      "Found 602 validated image filenames.\n",
      "Epoch 1/10\n",
      "75/75 [==============================] - 273s 4s/step - loss: 0.3209 - fbeta: 0.5310 - val_loss: 0.3335 - val_fbeta: 0.5030\n",
      "Epoch 2/10\n",
      "37/75 [=============>................] - ETA: 2:10 - loss: 0.3039 - fbeta: 0.5629"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-187-7c4762ca6bba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     73\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep_size_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                     epochs=10)\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ds-venv/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m                 \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m                 \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m                 initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m         \u001b[0;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ds-venv/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ds-venv/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ds-venv/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ds-venv/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ds-venv/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3727\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3729\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ds-venv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ds-venv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1591\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ds-venv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ds-venv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.virtualenvs/ds-venv/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "VALIDATION_FBETA = []\n",
    "VALIDATION_LOSS = []\n",
    "\n",
    "\n",
    "\n",
    "logs_dir = models_dir / 'logs' / model_type\n",
    "logs_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "save_dir = models_dir / model_type\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "fold_var = 1\n",
    "\n",
    "input_dim = 256\n",
    "output_dim = 11\n",
    "\n",
    "history_log_dict = defaultdict(int)\n",
    "\n",
    "for train_index, val_index in kf.split(np.zeros(n_samples),Y[:n_samples]):\n",
    "    # get the data that will be used for training in this fold\n",
    "    training_data = train_df.iloc[train_index]\n",
    "    # get the data that will be used for validation in this fold\n",
    "    validation_data = train_df.iloc[val_index]\n",
    "    \n",
    "    # now set up the generators to feed the data in batches to\n",
    "    # the model during training\n",
    "    \n",
    "    train_data_generator = idg.flow_from_dataframe(training_data,\n",
    "                                                  directory=raw_image_data_path,\n",
    "                                                  x_col = 'StudyInstanceUID',\n",
    "                                                  y_col=class_names,\n",
    "                                                  target_size = (input_dim,input_dim),\n",
    "                                                  color_mode='grayscale',\n",
    "                                                  class_mode='raw',\n",
    "                                                  batch_size=32,\n",
    "                                                  shuffle=True,\n",
    "                                                  seed=42)\n",
    "    valid_data_generator = idg.flow_from_dataframe(validation_data,\n",
    "                                                  directory=raw_image_data_path,\n",
    "                                                  x_col = 'StudyInstanceUID',\n",
    "                                                  y_col=class_names,\n",
    "                                                  target_size = (input_dim,input_dim),\n",
    "                                                  color_mode='grayscale',\n",
    "                                                  class_mode='raw',\n",
    "                                                  batch_size=32,\n",
    "                                                  shuffle=True,\n",
    "                                                  seed=42)\n",
    "    \n",
    "    \n",
    "    model = create_new_model(input_dim, output_dim)\n",
    "    \n",
    "    model._get_distribution_strategy = lambda: None\n",
    "    \n",
    "    \n",
    "    model_filepath = str(save_dir / get_model_name(fold_var))\n",
    "    \n",
    "    # Create callbacks below\n",
    "    callbacks_list = [\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "        filepath=model_filepath,\n",
    "        monitor=\"val_fbeta\",\n",
    "        save_best_only=True),\n",
    "        keras.callbacks.TensorBoard(\n",
    "        log_dir = logs_dir)\n",
    "    ]\n",
    "    \n",
    "    # Fitting the model\n",
    "    step_size_train = train_data_generator.n//train_data_generator.batch_size\n",
    "    step_size_val = valid_data_generator.n//valid_data_generator.batch_size\n",
    "    \n",
    "    # fit_generator is deprecated so we can use fit\n",
    "    history = model.fit(x=train_data_generator,\n",
    "                    steps_per_epoch=step_size_train,\n",
    "                    validation_data=valid_data_generator,\n",
    "                    validation_steps=step_size_val,\n",
    "                    callbacks=callbacks_list,\n",
    "                    epochs=30)\n",
    "    \n",
    "    \n",
    "    history_log_dict[fold_var] = history\n",
    "    \n",
    "    # now we will just locally load the best model from this fold\n",
    "    # and evaluate on the validation set \n",
    "    \n",
    "    model.load_weights(model_filepath)\n",
    "    \n",
    "    results = model.evaluate(valid_data_generator)\n",
    "    results = dict(zip(model.metrics_names, results))\n",
    "    \n",
    "    VALIDATION_FBETA.append(results[\"fbeta\"])\n",
    "    VALIDATION_LOSS.append(results[\"loss\"])\n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
