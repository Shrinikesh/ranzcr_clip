{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Python 2.7 reached the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 is no longer maintained. pip 21.0 will drop support for Python 2.7 in January 2021. More details about Python 2 support in pip can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support pip 21.0 will remove support for this functionality.\u001b[0m\n",
      "Requirement already satisfied: absl-py==0.9.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 1)) (0.9.0)\n",
      "Requirement already satisfied: appnope==0.1.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 2)) (0.1.0)\n",
      "Requirement already satisfied: arrow==0.15.6 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 3)) (0.15.6)\n",
      "Requirement already satisfied: astor==0.8.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 4)) (0.8.1)\n",
      "Requirement already satisfied: attrs==19.3.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 5)) (19.3.0)\n",
      "Requirement already satisfied: awscli==1.18.46 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 6)) (1.18.46)\n",
      "Requirement already satisfied: backcall==0.1.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 7)) (0.1.0)\n",
      "Requirement already satisfied: binaryornot==0.4.4 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 8)) (0.4.4)\n",
      "Requirement already satisfied: bleach==3.1.4 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 9)) (3.1.4)\n",
      "Requirement already satisfied: botocore==1.15.46 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 10)) (1.15.46)\n",
      "Requirement already satisfied: cachetools==3.1.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 11)) (3.1.1)\n",
      "Requirement already satisfied: certifi==2020.4.5.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 12)) (2020.4.5.1)\n",
      "Requirement already satisfied: chardet==3.0.4 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 13)) (3.0.4)\n",
      "Requirement already satisfied: click==7.1.2 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 14)) (7.1.2)\n",
      "Requirement already satisfied: colorama==0.4.3 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 15)) (0.4.3)\n",
      "Requirement already satisfied: cookiecutter==1.7.2 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 16)) (1.7.2)\n",
      "Requirement already satisfied: cycler==0.10.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 17)) (0.10.0)\n",
      "Requirement already satisfied: decorator==4.4.2 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 18)) (4.4.2)\n",
      "Requirement already satisfied: defusedxml==0.6.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 19)) (0.6.0)\n",
      "Requirement already satisfied: docutils==0.15.2 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 20)) (0.15.2)\n",
      "Requirement already satisfied: entrypoints==0.3 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 21)) (0.3)\n",
      "Requirement already satisfied: gast==0.2.2 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 22)) (0.2.2)\n",
      "Requirement already satisfied: google-auth==1.14.2 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 23)) (1.14.2)\n",
      "Requirement already satisfied: google-auth-oauthlib==0.4.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 24)) (0.4.1)\n",
      "Requirement already satisfied: google-pasta==0.2.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 25)) (0.2.0)\n",
      "Requirement already satisfied: grpcio==1.28.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 26)) (1.28.1)\n",
      "Requirement already satisfied: h5py==2.10.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 27)) (2.10.0)\n",
      "Requirement already satisfied: idna==2.9 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 28)) (2.9)\n",
      "Requirement already satisfied: importlib-metadata==1.6.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 29)) (1.6.0)\n",
      "Requirement already satisfied: ipykernel==4.10.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 30)) (4.10.1)\n",
      "Requirement already satisfied: ipython==5.10.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 31)) (5.10.0)\n",
      "Requirement already satisfied: ipython-genutils==0.2.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 32)) (0.2.0)\n",
      "Requirement already satisfied: ipywidgets==7.5.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 33)) (7.5.1)\n",
      "Requirement already satisfied: jedi==0.17.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 34)) (0.17.0)\n",
      "Requirement already satisfied: Jinja2==2.11.2 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 35)) (2.11.2)\n",
      "Requirement already satisfied: jinja2-time==0.2.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 36)) (0.2.0)\n",
      "Requirement already satisfied: jmespath==0.9.5 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 37)) (0.9.5)\n",
      "Requirement already satisfied: joblib==0.14.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 38)) (0.14.1)\n",
      "Requirement already satisfied: jsonschema==3.2.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 39)) (3.2.0)\n",
      "Requirement already satisfied: jupyter==1.0.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 40)) (1.0.0)\n",
      "Requirement already satisfied: jupyter-client==5.3.5 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 41)) (5.3.5)\n",
      "Requirement already satisfied: jupyter-console==5.2.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 42)) (5.2.0)\n",
      "Requirement already satisfied: jupyter-core==4.6.3 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 43)) (4.6.3)\n",
      "Requirement already satisfied: kaggle==1.5.10 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 44)) (1.5.10)\n",
      "Requirement already satisfied: Keras==2.3.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 45)) (2.3.1)\n",
      "Requirement already satisfied: Keras-Applications==1.0.8 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 46)) (1.0.8)\n",
      "Requirement already satisfied: Keras-Preprocessing==1.1.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 47)) (1.1.0)\n",
      "Requirement already satisfied: kiwisolver==1.1.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 48)) (1.1.0)\n",
      "Requirement already satisfied: Markdown==3.1.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 49)) (3.1.1)\n",
      "Requirement already satisfied: MarkupSafe==1.1.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 50)) (1.1.1)\n",
      "Requirement already satisfied: matplotlib==2.2.5 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 51)) (2.2.5)\n",
      "Requirement already satisfied: mistune==0.8.4 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 52)) (0.8.4)\n",
      "Requirement already satisfied: nbconvert==5.6.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 53)) (5.6.1)\n",
      "Requirement already satisfied: nbformat==4.4.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 54)) (4.4.0)\n",
      "Requirement already satisfied: notebook==5.7.10 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 55)) (5.7.10)\n",
      "Requirement already satisfied: numpy==1.16.6 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 56)) (1.16.6)\n",
      "Requirement already satisfied: oauthlib==3.1.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 57)) (3.1.0)\n",
      "Requirement already satisfied: opt-einsum==2.3.2 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 58)) (2.3.2)\n",
      "Requirement already satisfied: pandas==0.24.2 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 59)) (0.24.2)\n",
      "Requirement already satisfied: pandocfilters==1.4.2 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 60)) (1.4.2)\n",
      "Requirement already satisfied: parso==0.7.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 61)) (0.7.0)\n",
      "Collecting pathlib\n",
      "  Downloading pathlib-1.0.1.tar.gz (49 kB)\n",
      "\u001b[K     |████████████████████████████████| 49 kB 3.5 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: pexpect==4.8.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 63)) (4.8.0)\n",
      "Requirement already satisfied: pickleshare==0.7.5 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 64)) (0.7.5)\n",
      "Requirement already satisfied: Pillow==6.2.2 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 65)) (6.2.2)\n",
      "Requirement already satisfied: poyo==0.5.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 66)) (0.5.0)\n",
      "Requirement already satisfied: prometheus-client==0.7.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 67)) (0.7.1)\n",
      "Requirement already satisfied: prompt-toolkit==2.0.10 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 68)) (2.0.10)\n",
      "Requirement already satisfied: protobuf==3.11.3 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 69)) (3.11.3)\n",
      "Requirement already satisfied: ptyprocess==0.6.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 70)) (0.6.0)\n",
      "Requirement already satisfied: pyasn1==0.4.8 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 71)) (0.4.8)\n",
      "Requirement already satisfied: pyasn1-modules==0.2.8 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 72)) (0.2.8)\n",
      "Requirement already satisfied: Pygments==2.5.2 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 73)) (2.5.2)\n",
      "Requirement already satisfied: pyparsing==2.4.7 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 74)) (2.4.7)\n",
      "Requirement already satisfied: pyrsistent==0.16.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 75)) (0.16.0)\n",
      "Requirement already satisfied: python-dateutil==2.8.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 76)) (2.8.1)\n",
      "Requirement already satisfied: python-slugify==4.0.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 77)) (4.0.0)\n",
      "Requirement already satisfied: pytz==2019.3 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 78)) (2019.3)\n",
      "Requirement already satisfied: PyYAML==5.3.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 79)) (5.3.1)\n",
      "Requirement already satisfied: pyzmq==19.0.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 80)) (19.0.0)\n",
      "Requirement already satisfied: qtconsole==4.7.3 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 81)) (4.7.3)\n",
      "Requirement already satisfied: QtPy==1.9.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 82)) (1.9.0)\n",
      "Requirement already satisfied: requests==2.23.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 83)) (2.23.0)\n",
      "Requirement already satisfied: requests-oauthlib==1.3.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 84)) (1.3.0)\n",
      "Requirement already satisfied: rsa==4.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 85)) (4.0)\n",
      "Requirement already satisfied: s3transfer==0.3.3 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 86)) (0.3.3)\n",
      "Requirement already satisfied: scikit-learn==0.20.4 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 87)) (0.20.4)\n",
      "Requirement already satisfied: scipy==1.2.2 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 88)) (1.2.2)\n",
      "Requirement already satisfied: seaborn==0.9.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 89)) (0.9.1)\n",
      "Requirement already satisfied: Send2Trash==1.5.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 90)) (1.5.0)\n",
      "Requirement already satisfied: six==1.14.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 91)) (1.14.0)\n",
      "Requirement already satisfied: tensorboard==2.1.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 92)) (2.1.0)\n",
      "Requirement already satisfied: tensorflow==2.1.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 93)) (2.1.0)\n",
      "Requirement already satisfied: tensorflow-estimator==2.1.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 94)) (2.1.0)\n",
      "Requirement already satisfied: termcolor==1.1.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 95)) (1.1.0)\n",
      "Requirement already satisfied: testpath==0.4.4 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 96)) (0.4.4)\n",
      "Requirement already satisfied: text-unidecode==1.3 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 97)) (1.3)\n",
      "Requirement already satisfied: tornado==5.1.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 98)) (5.1.1)\n",
      "Requirement already satisfied: tqdm==4.54.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 99)) (4.54.1)\n",
      "Requirement already satisfied: traitlets==4.3.3 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 100)) (4.3.3)\n",
      "Requirement already satisfied: urllib3==1.25.9 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 101)) (1.25.9)\n",
      "Requirement already satisfied: wcwidth==0.1.9 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 102)) (0.1.9)\n",
      "Requirement already satisfied: webencodings==0.5.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 103)) (0.5.1)\n",
      "Requirement already satisfied: Werkzeug==1.0.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 104)) (1.0.1)\n",
      "Requirement already satisfied: widgetsnbextension==3.5.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 105)) (3.5.1)\n",
      "Requirement already satisfied: wrapt==1.12.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 106)) (1.12.1)\n",
      "Requirement already satisfied: zipp==1.2.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from -r ../requirements.txt (line 107)) (1.2.0)\n",
      "Requirement already satisfied: enum34; python_version < \"3.4\" in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from absl-py==0.9.0->-r ../requirements.txt (line 1)) (1.1.6)\n",
      "Requirement already satisfied: backports.functools-lru-cache>=1.2.1; python_version == \"2.7\" in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from arrow==0.15.6->-r ../requirements.txt (line 3)) (1.5)\n",
      "Requirement already satisfied: whichcraft>=0.4.0; python_version < \"3.3\" in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from cookiecutter==1.7.2->-r ../requirements.txt (line 16)) (0.6.1)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from google-auth==1.14.2->-r ../requirements.txt (line 23)) (41.4.0)\n",
      "Requirement already satisfied: futures>=2.2.0; python_version < \"3.2\" in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from grpcio==1.28.1->-r ../requirements.txt (line 26)) (3.3.0)\n",
      "Requirement already satisfied: pathlib2; python_version < \"3\" in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from importlib-metadata==1.6.0->-r ../requirements.txt (line 29)) (2.3.5)\n",
      "Requirement already satisfied: contextlib2; python_version < \"3\" in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from importlib-metadata==1.6.0->-r ../requirements.txt (line 29)) (0.6.0)\n",
      "Requirement already satisfied: configparser>=3.5; python_version < \"3\" in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from importlib-metadata==1.6.0->-r ../requirements.txt (line 29)) (4.0.2)\n",
      "Requirement already satisfied: backports.shutil-get-terminal-size; python_version == \"2.7\" in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from ipython==5.10.0->-r ../requirements.txt (line 31)) (1.0.0)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from ipython==5.10.0->-r ../requirements.txt (line 31)) (0.8.1)\n",
      "Requirement already satisfied: functools32; python_version < \"3\" in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from jsonschema==3.2.0->-r ../requirements.txt (line 39)) (3.2.3.post2)\n",
      "Requirement already satisfied: subprocess32 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from matplotlib==2.2.5->-r ../requirements.txt (line 51)) (3.5.4)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from notebook==5.7.10->-r ../requirements.txt (line 55)) (0.8.2)\n",
      "Requirement already satisfied: ipaddress; python_version == \"2.7\" in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from notebook==5.7.10->-r ../requirements.txt (line 55)) (1.0.22)\n",
      "Requirement already satisfied: wheel; python_version < \"3\" in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from tensorboard==2.1.0->-r ../requirements.txt (line 92)) (0.33.6)\n",
      "Requirement already satisfied: backports.weakref>=1.0rc1; python_version < \"3.4\" in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from tensorflow==2.1.0->-r ../requirements.txt (line 93)) (1.0.post1)\n",
      "Requirement already satisfied: mock>=2.0.0; python_version < \"3\" in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from tensorflow==2.1.0->-r ../requirements.txt (line 93)) (3.0.5)\n",
      "Requirement already satisfied: singledispatch in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from tornado==5.1.1->-r ../requirements.txt (line 98)) (3.4.0.3)\n",
      "Requirement already satisfied: backports_abc>=0.4 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from tornado==5.1.1->-r ../requirements.txt (line 98)) (0.5)\n",
      "Requirement already satisfied: scandir; python_version < \"3.5\" in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from pathlib2; python_version < \"3\"->importlib-metadata==1.6.0->-r ../requirements.txt (line 29)) (1.10.0)\n",
      "Requirement already satisfied: funcsigs>=1; python_version < \"3.3\" in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from mock>=2.0.0; python_version < \"3\"->tensorflow==2.1.0->-r ../requirements.txt (line 93)) (1.0.2)\n",
      "Building wheels for collected packages: pathlib\n",
      "  Building wheel for pathlib (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pathlib: filename=pathlib-1.0.1-py2-none-any.whl size=14347 sha256=e7dba901708ec64559984eb7feb6802d8b479f0f825a639b64800361a92e2d92\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/46/37/4f/332bcea757140ff34e14dec7be65931f544c7ac94eb671ae9f\n",
      "Successfully built pathlib\n",
      "Installing collected packages: pathlib\n",
      "Successfully installed pathlib-1.0.1\n",
      "\u001b[33mWARNING: You are using pip version 20.3; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import ast\n",
    "from sklearn.model_selection import KFold\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from keras import layers, Input\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "import keras\n",
    "from keras import backend\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handlers could be found for logger \"sagemaker\"\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'basic_convnet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Before defining the model, we will define an fbeta metric that we will monitor which we will use as a proxy for the average AUROC across the 11 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fbeta(y_true, y_pred, beta=2):\n",
    "    # taken from https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-to-classify-satellite-photos-of-the-amazon-rainforest/\n",
    "    #clip predictions (incase our output layer is not bound to [0,1])\n",
    "    y_pred = backend.clip(y_pred, 0, 1)\n",
    "    # calculate tp, fp and fn for each class\n",
    "    tp = backend.sum(backend.round(backend.clip(y_true * y_pred, 0, 1)), axis=1)\n",
    "    fp = backend.sum(backend.round(backend.clip(y_pred - y_true, 0, 1)), axis=1)\n",
    "    fn = backend.sum(backend.round(backend.clip(y_true - y_pred, 0, 1)), axis=1)\n",
    "    # calculate precision\n",
    "    p = tp / (tp + fp + backend.epsilon())\n",
    "    # calculate recall\n",
    "    r = tp / (tp + fn + backend.epsilon())\n",
    "    # calculate fbeta, averaged across each class\n",
    "    bb = beta ** 2\n",
    "    fbeta_score = backend.mean((1 + bb) * (p * r) / (bb * p + r + backend.epsilon()))\n",
    "    return fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_model(input_dim, output_dim):\n",
    "    input_tensor = Input(shape=(input_dim,input_dim,1))\n",
    "    y = layers.Conv2D(32, (3,3), padding='same', activation='relu')(input_tensor)\n",
    "    y = layers.MaxPooling2D(2, strides=2)(y)\n",
    "    y = layers.Conv2D(32, (3,3), padding='same', activation='relu')(y)\n",
    "    y = layers.MaxPooling2D(2, strides=2)(y)\n",
    "    y = layers.Dropout(0.25)(y)\n",
    "    \n",
    "    y = layers.Conv2D(64, (3,3), padding='same', activation='relu')(y)\n",
    "    y = layers.MaxPooling2D(2, strides=2)(y)\n",
    "    y = layers.Conv2D(128, (3,3), padding='same', activation='relu')(y)\n",
    "    y = layers.MaxPooling2D(2, strides=2)(y)\n",
    "    y = layers.Dropout(0.25)(y)\n",
    "    \n",
    "    y = layers.Flatten()(y)\n",
    "    y = layers.Dense(512, activation= 'relu')(y)\n",
    "    y = layers.Dropout(0.5)(y)\n",
    "    output_tensor = layers.Dense(output_dim, activation='sigmoid')(y)\n",
    "    \n",
    "    model = Model(input_tensor, output_tensor)\n",
    "    \n",
    "    \n",
    "    model.compile(optimizers.rmsprop(lr=0.0001, decay=1e-6),\n",
    "                 loss=\"binary_crossentropy\", metrics = [fbeta])\n",
    "    \n",
    "    return model\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_path = Path('/Users/Shrinikesh/Documents/personal-projects/kaggle/ranzcr_clip/data/raw')\n",
    "raw_image_data_path = Path('/Users/Shrinikesh/Documents/personal-projects/kaggle/ranzcr_clip/data/raw/train')\n",
    "models_dir = Path('/Users/Shrinikesh/Documents/personal-projects/kaggle/ranzcr_clip/models')\n",
    "train_data_path = raw_data_path / 'train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30083, 13)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will drop PatientID for now as it is not included in test images. Perhaps we can incorporate the information later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Moreover, as we need the filenames in full to use the flow_from_dataframe function for training, we will append the extension to all the StudyInstanceUIDs (.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_ext(fn):\n",
    "    return fn+\".jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>ETT - Abnormal</th>\n",
       "      <th>ETT - Borderline</th>\n",
       "      <th>ETT - Normal</th>\n",
       "      <th>NGT - Abnormal</th>\n",
       "      <th>NGT - Borderline</th>\n",
       "      <th>NGT - Incompletely Imaged</th>\n",
       "      <th>NGT - Normal</th>\n",
       "      <th>CVC - Abnormal</th>\n",
       "      <th>CVC - Borderline</th>\n",
       "      <th>CVC - Normal</th>\n",
       "      <th>Swan Ganz Catheter Present</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.826.0.1.3680043.8.498.26697628953273228189...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2.826.0.1.3680043.8.498.46302891597398758759...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.826.0.1.3680043.8.498.23819260719748494858...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.2.826.0.1.3680043.8.498.68286643202323212801...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.2.826.0.1.3680043.8.498.10050203009225938259...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    StudyInstanceUID  ETT - Abnormal  \\\n",
       "0  1.2.826.0.1.3680043.8.498.26697628953273228189...               0   \n",
       "1  1.2.826.0.1.3680043.8.498.46302891597398758759...               0   \n",
       "2  1.2.826.0.1.3680043.8.498.23819260719748494858...               0   \n",
       "3  1.2.826.0.1.3680043.8.498.68286643202323212801...               0   \n",
       "4  1.2.826.0.1.3680043.8.498.10050203009225938259...               0   \n",
       "\n",
       "   ETT - Borderline  ETT - Normal  NGT - Abnormal  NGT - Borderline  \\\n",
       "0                 0             0               0                 0   \n",
       "1                 0             1               0                 0   \n",
       "2                 0             0               0                 0   \n",
       "3                 0             0               0                 0   \n",
       "4                 0             0               0                 0   \n",
       "\n",
       "   NGT - Incompletely Imaged  NGT - Normal  CVC - Abnormal  CVC - Borderline  \\\n",
       "0                          0             1               0                 0   \n",
       "1                          1             0               0                 0   \n",
       "2                          0             0               0                 1   \n",
       "3                          0             0               1                 0   \n",
       "4                          0             0               0                 0   \n",
       "\n",
       "   CVC - Normal  Swan Ganz Catheter Present  \n",
       "0             0                           0  \n",
       "1             1                           0  \n",
       "2             0                           0  \n",
       "3             0                           0  \n",
       "4             1                           0  "
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_df['PatientID']\n",
    "\n",
    "train_df['StudyInstanceUID'] = train_df['StudyInstanceUID'].apply(append_ext)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = list(train_df.columns)\n",
    "class_names.remove('StudyInstanceUID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will create a class to index mapping so that the model will work irrespective of the order of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping = {class_names[i]:i for i in range(len(class_names))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ETT - Abnormal': 0,\n",
       " 'ETT - Borderline': 1,\n",
       " 'ETT - Normal': 2,\n",
       " 'NGT - Abnormal': 3,\n",
       " 'NGT - Borderline': 4,\n",
       " 'NGT - Incompletely Imaged': 5,\n",
       " 'NGT - Normal': 6,\n",
       " 'CVC - Abnormal': 7,\n",
       " 'CVC - Borderline': 8,\n",
       " 'CVC - Normal': 9,\n",
       " 'Swan Ganz Catheter Present': 10}"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will use stratified K-Fold validation for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to one hot encode each example's\n",
    "# labels as an array using the mapping\n",
    "\n",
    "def one_hot_encode(example_labels_dict, mapping=class_mapping):\n",
    "    encoding = np.zeros(len(mapping), dtype='uint8')\n",
    "    for label, value in example_labels_dict.items():\n",
    "        if value:\n",
    "            encoding[mapping[label]] = 1\n",
    "    return encoding        \n",
    "            \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = train_df[class_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 3\n",
    "\n",
    "kf = KFold(n_splits = n_splits, random_state = 7, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define percentage of overall data to use for training here (just as using all the data for training might take too long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_use_percent = 0.2\n",
    "\n",
    "n_samples = int(np.ceil(train_df.shape[0]*train_use_percent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6017"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will use ImageDataGenerator to turn our images into batches of preprocessed training and validation images during each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "idg = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We also need to save the best model during each fold, so will also create a function here that creates a model name for each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_name(k):\n",
    "    return 'model_{}.h5'.format(str(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAIN TRAINING LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2407 validated image filenames.\n",
      "Found 602 validated image filenames.\n",
      "Epoch 1/10\n",
      "75/75 [==============================] - 273s 4s/step - loss: 0.3209 - fbeta: 0.5310 - val_loss: 0.3335 - val_fbeta: 0.5030\n",
      "Epoch 2/10\n",
      "37/75 [=============>................] - ETA: 2:10 - loss: 0.3039 - fbeta: 0.5629"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-187-7c4762ca6bba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     73\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep_size_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                     epochs=10)\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ds-venv/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m                 \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m                 \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m                 initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m         \u001b[0;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ds-venv/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ds-venv/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ds-venv/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ds-venv/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ds-venv/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3727\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3729\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ds-venv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ds-venv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1591\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ds-venv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ds-venv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.virtualenvs/ds-venv/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "VALIDATION_FBETA = []\n",
    "VALIDATION_LOSS = []\n",
    "\n",
    "\n",
    "\n",
    "logs_dir = models_dir / 'logs' / model_type\n",
    "logs_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "save_dir = models_dir / model_type\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "fold_var = 1\n",
    "\n",
    "input_dim = 256\n",
    "output_dim = 11\n",
    "\n",
    "history_log_dict = defaultdict(int)\n",
    "\n",
    "for train_index, val_index in kf.split(np.zeros(n_samples),Y[:n_samples]):\n",
    "    # get the data that will be used for training in this fold\n",
    "    training_data = train_df.iloc[train_index]\n",
    "    # get the data that will be used for validation in this fold\n",
    "    validation_data = train_df.iloc[val_index]\n",
    "    \n",
    "    # now set up the generators to feed the data in batches to\n",
    "    # the model during training\n",
    "    \n",
    "    train_data_generator = idg.flow_from_dataframe(training_data,\n",
    "                                                  directory=raw_image_data_path,\n",
    "                                                  x_col = 'StudyInstanceUID',\n",
    "                                                  y_col=class_names,\n",
    "                                                  target_size = (input_dim,input_dim),\n",
    "                                                  color_mode='grayscale',\n",
    "                                                  class_mode='raw',\n",
    "                                                  batch_size=32,\n",
    "                                                  shuffle=True,\n",
    "                                                  seed=42)\n",
    "    valid_data_generator = idg.flow_from_dataframe(validation_data,\n",
    "                                                  directory=raw_image_data_path,\n",
    "                                                  x_col = 'StudyInstanceUID',\n",
    "                                                  y_col=class_names,\n",
    "                                                  target_size = (input_dim,input_dim),\n",
    "                                                  color_mode='grayscale',\n",
    "                                                  class_mode='raw',\n",
    "                                                  batch_size=32,\n",
    "                                                  shuffle=True,\n",
    "                                                  seed=42)\n",
    "    \n",
    "    \n",
    "    model = create_new_model(input_dim, output_dim)\n",
    "    \n",
    "    model._get_distribution_strategy = lambda: None\n",
    "    \n",
    "    \n",
    "    model_filepath = str(save_dir / get_model_name(fold_var))\n",
    "    \n",
    "    # Create callbacks below\n",
    "    callbacks_list = [\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "        filepath=model_filepath,\n",
    "        monitor=\"val_fbeta\",\n",
    "        save_best_only=True),\n",
    "        keras.callbacks.TensorBoard(\n",
    "        log_dir = logs_dir)\n",
    "    ]\n",
    "    \n",
    "    # Fitting the model\n",
    "    step_size_train = train_data_generator.n//train_data_generator.batch_size\n",
    "    step_size_val = valid_data_generator.n//valid_data_generator.batch_size\n",
    "    \n",
    "    # fit_generator is deprecated so we can use fit\n",
    "    history = model.fit(x=train_data_generator,\n",
    "                    steps_per_epoch=step_size_train,\n",
    "                    validation_data=valid_data_generator,\n",
    "                    validation_steps=step_size_val,\n",
    "                    callbacks=callbacks_list,\n",
    "                    epochs=30)\n",
    "    \n",
    "    \n",
    "    history_log_dict[fold_var] = history\n",
    "    \n",
    "    # now we will just locally load the best model from this fold\n",
    "    # and evaluate on the validation set \n",
    "    \n",
    "    model.load_weights(model_filepath)\n",
    "    \n",
    "    results = model.evaluate(valid_data_generator)\n",
    "    results = dict(zip(model.metrics_names, results))\n",
    "    \n",
    "    VALIDATION_FBETA.append(results[\"fbeta\"])\n",
    "    VALIDATION_LOSS.append(results[\"loss\"])\n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p27",
   "language": "python",
   "name": "conda_amazonei_mxnet_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
